[2024-07-03T23:19:17.180+0000] {scheduler_job_runner.py:1737} ERROR - Detected zombie job: {'full_filepath': '/opt/airflow/dags/my_dag.py', 'processor_subdir': '/opt/airflow/dags', 'msg': "{'DAG Id': 'exchange_rate_dag', 'Task Id': 'run_script', 'Run Id': 'scheduled__2024-03-26T00:00:00+00:00', 'Hostname': '0b7358cba041', 'External Executor Id': '696b5872-c0b6-4168-af7a-06d7d3dc9f84'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7f48e9a5a630>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
[2024-07-05T01:30:51.047+0000] {scheduler_job_runner.py:769} ERROR - Executor reports task instance <TaskInstance: exchange_rate_dag.run_script scheduled__2024-03-26T00:00:00+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
